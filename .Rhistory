rf_A_fit <- rf_A_wf %>% fit(A_train)
# ---- Model B RF: predict percent_pi ----
rf_B_rec <- recipe(percent_pi ~
ili_lag1 + ili_lag2 + ili_lag3 + ili_lag4 +
t2m_lag1 + t2m_lag2 + t2m_lag3 + t2m_lag4 +
rh2m_lag1 + rh2m_lag2 + rh2m_lag3 + rh2m_lag4 +
precip_lag1 + precip_lag2 + precip_lag3 + precip_lag4,
data = B_train) %>%
step_impute_median(all_numeric_predictors())
rf_B_wf <- workflow() %>%
add_model(rf_spec) %>%
add_recipe(rf_B_rec)
rf_B_fit <- rf_B_wf %>% fit(B_train)
## ------------------------------------------------------------------
## 5. ARIMA, ARIMAX FOR NE-AGGREGATE percent_pi
## ------------------------------------------------------------------
# Aggregate B data across states by year + week
B_agg <- model_B %>%
group_by(year, week) %>%
summarise(
percent_pi = mean(percent_pi, na.rm = TRUE),   # <-- new target
ili        = mean(unweighted_ili, na.rm = TRUE),
t2m        = mean(t2m_mean,       na.rm = TRUE),
rh2m       = mean(rh2m_mean,      na.rm = TRUE),
precip     = mean(precip_sum,     na.rm = TRUE),
.groups    = "drop"
) %>%
arrange(year, week)
# Pre-pandemic subset (for "clean" training)
B_agg_pre <- B_agg %>% filter(year <= 2019)
# Weekly time series of Percent PI
pi_ts_pre <- ts(B_agg_pre$percent_pi, frequency = 52)
## 5.1 ARIMA (pi percent ~ past pi_deaths only)
arima_pi <- auto.arima(pi_ts_pre)
library(forecast)
#Using ML Models
set.seed(123)
## ------------------------------------------------------------------
## LINEAR MODELS (LM)
## ------------------------------------------------------------------
# ---- Model A LM: predict unweighted_ili ----
lm_A_rec <- recipe(unweighted_ili ~
ili_lag1 + ili_lag2 + ili_lag3 + ili_lag4 +
t2m_lag1 + t2m_lag2 + t2m_lag3 + t2m_lag4 +
rh2m_lag1 + rh2m_lag2 + rh2m_lag3 + rh2m_lag4 +
precip_lag1 + precip_lag2 + precip_lag3 + precip_lag4,
data = A_train) %>%
step_impute_median(all_numeric_predictors()) %>%
step_normalize(all_numeric_predictors())
lm_spec <- linear_reg() %>%
set_engine("lm")
lm_A_wf <- workflow() %>%
add_model(lm_spec) %>%
add_recipe(lm_A_rec)
lm_A_fit <- lm_A_wf %>% fit(A_train)
# ---- Model B LM: predict percent_pi ----
lm_B_rec <- recipe(percent_pi ~
ili_lag1 + ili_lag2 + ili_lag3 + ili_lag4 +
t2m_lag1 + t2m_lag2 + t2m_lag3 + t2m_lag4 +
rh2m_lag1 + rh2m_lag2 + rh2m_lag3 + rh2m_lag4 +
precip_lag1 + precip_lag2 + precip_lag3 + precip_lag4,
data = B_train) %>%
step_impute_median(all_numeric_predictors()) %>%
step_normalize(all_numeric_predictors())
lm_B_wf <- workflow() %>%
add_model(lm_spec) %>%
add_recipe(lm_B_rec)
lm_B_fit <- lm_B_wf %>% fit(B_train)
## ------------------------------------------------------------------
## RANDOM FOREST MODELS (RF) + FEATURE IMPORTANCE
## ------------------------------------------------------------------
rf_spec <- rand_forest(
mtry  = 6,
min_n = 5,
trees = 500
) %>%
set_mode("regression") %>%
# importance = "impurity" exposes variable.importance in ranger object
set_engine("ranger", importance = "impurity")
# ---- Model A RF: predict unweighted_ili ----
rf_A_rec <- recipe(unweighted_ili ~
ili_lag1 + ili_lag2 + ili_lag3 + ili_lag4 +
t2m_lag1 + t2m_lag2 + t2m_lag3 + t2m_lag4 +
rh2m_lag1 + rh2m_lag2 + rh2m_lag3 + rh2m_lag4 +
precip_lag1 + precip_lag2 + precip_lag3 + precip_lag4,
data = A_train) %>%
step_impute_median(all_numeric_predictors())
rf_A_wf <- workflow() %>%
add_model(rf_spec) %>%
add_recipe(rf_A_rec)
rf_A_fit <- rf_A_wf %>% fit(A_train)
# ---- Model B RF: predict percent_pi ----
rf_B_rec <- recipe(percent_pi ~
ili_lag1 + ili_lag2 + ili_lag3 + ili_lag4 +
t2m_lag1 + t2m_lag2 + t2m_lag3 + t2m_lag4 +
rh2m_lag1 + rh2m_lag2 + rh2m_lag3 + rh2m_lag4 +
precip_lag1 + precip_lag2 + precip_lag3 + precip_lag4,
data = B_train) %>%
step_impute_median(all_numeric_predictors())
rf_B_wf <- workflow() %>%
add_model(rf_spec) %>%
add_recipe(rf_B_rec)
rf_B_fit <- rf_B_wf %>% fit(B_train)
## ------------------------------------------------------------------
## 5. ARIMA, ARIMAX FOR NE-AGGREGATE percent_pi
## ------------------------------------------------------------------
# Aggregate B data across states by year + week
B_agg <- model_B %>%
group_by(year, week) %>%
summarise(
percent_pi = mean(percent_pi, na.rm = TRUE),   # <-- new target
ili        = mean(unweighted_ili, na.rm = TRUE),
t2m        = mean(t2m_mean,       na.rm = TRUE),
rh2m       = mean(rh2m_mean,      na.rm = TRUE),
precip     = mean(precip_sum,     na.rm = TRUE),
.groups    = "drop"
) %>%
arrange(year, week)
# Pre-pandemic subset (for "clean" training)
B_agg_pre <- B_agg %>% filter(year <= 2019)
# Weekly time series of Percent PI
pi_ts_pre <- ts(B_agg_pre$percent_pi, frequency = 52)
## 5.1 ARIMA (pi percent ~ past pi_deaths only)
arima_pi <- auto.arima(pi_ts_pre)
summary(arima_pi)
## 5.2 ARIMAX (pi_deaths ~ past climate & ILI)
# Build lagged regressors for ARIMAX
B_agg_pre_lag <- B_agg_pre %>%
mutate(
ili_lag1   = lag(ili, 1),
t2m_lag1   = lag(t2m, 1),
rh2m_lag1  = lag(rh2m, 1),
precip_lag1 = lag(precip, 1)
) %>%
filter(!is.na(ili_lag1))   # drop first row where lags are NA
y_arimax <- ts(B_agg_pre_lag$percent_pi, frequency = 52)
X_arimax <- as.matrix(B_agg_pre_lag[, c(
"ili_lag1",
"t2m_lag1",
"rh2m_lag1",
"precip_lag1")])
arimax_pi <- auto.arima(y_arimax, xreg = X_arimax)
summary(arimax_pi)
fc_arima  <- forecast::forecast(arima_pi, h = 52)
## ------------------------------------------------------------------
## 5b. ARIMA, ARIMAX FOR NE-AGGREGATE ILI (Model A)
## ------------------------------------------------------------------
# Aggregate A data across states by year + week
A_agg <- model_df_A %>%
group_by(year, week) %>%
summarise(
ili       = mean(unweighted_ili, na.rm = TRUE),
t2m       = mean(t2m_mean,       na.rm = TRUE),
rh2m      = mean(rh2m_mean,      na.rm = TRUE),
precip    = mean(precip_sum,     na.rm = TRUE),
.groups   = "drop"
) %>%
arrange(year, week)
# Pre-pandemic subset
A_agg_pre <- A_agg %>% filter(year <= 2019)
# Weekly time series for ILI (Model A target)
ili_ts_pre <- ts(A_agg_pre$ili, frequency = 52)
## 5.1 ARIMA (ILI ~ past ILI)
arima_ili <- auto.arima(ili_ts_pre)
summary(arima_ili)
## 5.2 ARIMAX (ILI ~ climate + lagged ILI)
A_agg_pre_lag <- A_agg_pre %>%
mutate(
ili_lag1   = lag(ili, 1),   # autoregressive term
t2m_lag1   = lag(t2m, 1),
rh2m_lag1  = lag(rh2m, 1),
precip_lag1 = lag(precip, 1)
) %>%
filter(!is.na(ili_lag1))   # drop initial NA row
y_arimax_A <- ts(A_agg_pre_lag$ili, frequency = 52)
X_arimax_A <- as.matrix(A_agg_pre_lag[, c(
"ili_lag1",
"t2m_lag1",
"rh2m_lag1",
"precip_lag1"
)])
arimax_ili <- auto.arima(y_arimax_A, xreg = X_arimax_A)
summary(arimax_ili)
fc_arima_A  <- forecast::forecast(arima_ili, h = 52)
model_metrics <- function(true, pred) {
tibble(
RMSE  = rmse_vec(true, pred),
MAE   = mae_vec(true, pred),
MAPE  = mape_vec(true, pred),
Rsq   = rsq_vec(true, pred))}
## Generate predictions for LM and RF (Model A + Model B)
#MODEL A: predict unweighted_ili
# Predictions: PRE-PANDEMIC
A_train$pred_lm  <- predict(lm_A_fit,  A_train)$.pred
A_train$pred_rf  <- predict(rf_A_fit,  A_train)$.pred
# PANDEMIC (2020–2021)
A_pand$pred_lm <- predict(lm_A_fit, A_pand)$.pred
A_pand$pred_rf <- predict(rf_A_fit, A_pand)$.pred
# POST-PANDEMIC (2022–2024)
A_post$pred_lm <- predict(lm_A_fit, A_post)$.pred
A_post$pred_rf <- predict(rf_A_fit, A_post)$.pred
A_perf <- bind_rows(
model_metrics(A_train$unweighted_ili, A_train$pred_lm)  %>% mutate(model="LM", period="Train"),
model_metrics(A_pand$unweighted_ili,  A_pand$pred_lm)   %>% mutate(model="LM", period="Pandemic"),
model_metrics(A_post$unweighted_ili,  A_post$pred_lm)   %>% mutate(model="LM", period="Post"),
model_metrics(A_train$unweighted_ili, A_train$pred_rf)  %>% mutate(model="RF", period="Train"),
model_metrics(A_pand$unweighted_ili,  A_pand$pred_rf)   %>% mutate(model="RF", period="Pandemic"),
model_metrics(A_post$unweighted_ili,  A_post$pred_rf)   %>% mutate(model="RF", period="Post")
)
A_perf
#MODEL B: predict percent_pi
# PRE-PANDEMIC
B_train$pred_lm <- predict(lm_B_fit, B_train)$.pred
B_train$pred_rf <- predict(rf_B_fit, B_train)$.pred
# PANDEMIC
B_pand$pred_lm <- predict(lm_B_fit, B_pand)$.pred
B_pand$pred_rf <- predict(rf_B_fit, B_pand)$.pred
# POST-PANDEMIC
B_post$pred_lm <- predict(lm_B_fit, B_post)$.pred
B_post$pred_rf <- predict(rf_B_fit, B_post)$.pred
B_perf <- bind_rows(
model_metrics(B_train$percent_pi, B_train$pred_lm)  %>% mutate(model="LM", period="Train"),
model_metrics(B_pand$percent_pi,  B_pand$pred_lm)   %>% mutate(model="LM", period="Pandemic"),
model_metrics(B_post$percent_pi,  B_post$pred_lm)   %>% mutate(model="LM", period="Post"),
model_metrics(B_train$percent_pi, B_train$pred_rf)  %>% mutate(model="RF", period="Train"),
model_metrics(B_pand$percent_pi,  B_pand$pred_rf)   %>% mutate(model="RF", period="Pandemic"),
model_metrics(B_post$percent_pi,  B_post$pred_rf)   %>% mutate(model="RF", period="Post")
)
B_perf
## ------------------------------------------------------------------
## 4a. FEATURE IMPORTANCE: which lags drive pi_percent and unweighted_ili?
## ------------------------------------------------------------------
# Extract underlying ranger model
rf_A_fit_obj <- rf_A_fit %>% extract_fit_parsnip()
# Pull variable importance
rf_A_imp <- rf_A_fit_obj$fit$variable.importance
# Convert to tidy tibble
rf_A_imp_df <- tibble(
predictor  = names(rf_A_imp),
importance = as.numeric(rf_A_imp)
) %>%
arrange(desc(importance))
# View ranked importance
rf_A_imp_df
rf_A_imp_df %>%
slice_max(importance, n = 15) %>%
ggplot(aes(x = reorder(predictor, importance), y = importance)) +
geom_col(fill = "#2C7BB6") +
coord_flip() +
labs(
title = "Random Forest (Model A): Variable Importance for unweighted_ili",
x = "Lagged predictor",
y = "Importance (impurity decrease)"
) +
theme_minimal(base_size = 13)
#For model B
rf_B_fit_obj <- rf_B_fit %>% extract_fit_parsnip()
rf_B_imp <- rf_B_fit_obj$fit$variable.importance
rf_B_imp_df <- tibble(
predictor  = names(rf_B_imp),
importance = as.numeric(rf_B_imp)
) %>%
arrange(desc(importance))
# View ranked importance
rf_B_imp_df
# Plot top 15 predictors (you will see which lags dominate)
rf_B_imp_df %>%
slice_max(importance, n = 15) %>%
ggplot(aes(x = reorder(predictor, importance), y = importance)) +
geom_col() +
coord_flip() +
labs(
title = "Random Forest (Model B): Variable Importance for pi_deaths",
x = "Lagged predictor",
y = "Importance (impurity decrease)"
)
#Model perfomance
bind_rows(
A_perf %>% mutate(target = "ILI"),
B_perf %>% mutate(target = "Percent PI")
) %>%
ggplot(aes(x = period, y = RMSE, fill = model)) +
geom_col(position = "dodge") +
facet_wrap(~ target, scales = "free_y") +
labs(
title = "Model Performance Across Periods",
y = "RMSE",
x = "Period"
) +
theme_minimal(base_size = 14) +
scale_fill_brewer(palette = "Set2")
## Generate predictions for ARIMA Model
y_train <- B_agg_pre$percent_pi
# Forecast horizon = number of pandemic + post weeks
h_pand  <- nrow(B_agg %>% filter(year %in% 2020:2021))
h_post  <- nrow(B_agg %>% filter(year >= 2022))
# Forecasting
fc_arima_B <- forecast(arima_pi, h = h_pand + h_post)
# Extract predicted values
pred_arima <- fc_arima_B$mean
true_future <- B_agg %>% filter(year >= 2020) %>% pull(percent_pi)
# performance
arima_perf_B <- model_metrics(true_future, pred_arima[1:length(true_future)])
arima_perf_B
#Similar for A
fc_arima_A <- forecast(arima_ili, h = nrow(A_agg %>% filter(year >= 2020)))
pred_arima_A <- fc_arima_A$mean
true_A <- A_agg %>% filter(year >= 2020) %>% pull(ili)
arima_perf_A <- model_metrics(true_A, pred_arima_A[1:length(true_A)])
arima_perf_A
##############################################################
#Plots for the ARIMA Models#
##############################################################
autoplot(fc_arima) +
labs(
title = "ARIMA Forecast: Percent PI",
x = "Week",
y = "Percent PI"
) +
theme_minimal()
autoplot(fc_arima_A) +
labs(
title = "ARIMA Forecast: Percent PI",
x = "Week",
y = "Unweighted ILI"
) +
theme_minimal()
saveRDS(full_df, "full_df.rds")
saveRDS(ne_geom, "ne_geom.rds")
saveRDS(lm_A_fit, "lm_A_fit.rds")
saveRDS(lm_B_fit, "lm_B_fit.rds")
saveRDS(rf_A_fit, "rf_A_fit.rds")
saveRDS(rf_B_fit, "rf_B_fit.rds")
saveRDS(A_perf, "A_perf.rds")
saveRDS(B_perf, "B_perf.rds")
saveRDS(rf_A_imp_df, "rf_A_imp_df.rds")
saveRDS(rf_B_imp_df, "rf_B_imp_df.rds")
saveRDS(fc_arima_A, "fc_arima_A.rds")
saveRDS(fc_arima, "fc_arima.rds")
full_df <- ili_tbl %>%
left_join(mort_tbl, by = c("state_id","state_abbr","year","week")) %>%
left_join(clim_tbl, by = c("state_id","state_abbr","year","week")) %>%
arrange(state_name, year, week)
full_df <- ili_tbl %>%
left_join(mort_tbl, by = c("state_id","state_abbr","year","week")) %>%
left_join(clim_WK, by = c("state_id","state_abbr","year","week")) %>%
arrange(state_name, year, week)
#Building Data for modeling (for combined Mortality/OPD/Climate)
## ILI ~ climate + mortality (2016–2024)
ili_tbl  <- tbl(con, "ili")
mort_tbl <- tbl(con, "mortality")
clim_wk  <- tbl(con, "climate_weekly")
model_df <- ili_tbl %>%
inner_join(
mort_tbl,
by = c("state_id", "state_abbr", "year", "week", "region")
) %>%
inner_join(
clim_wk,
by = c(
"state_id",
"state_abbr",
"year",
"week",
region = "state_name"
)
) %>%
select(
state_id,
state_name = region,
state_abbr,
year,
week,
weighted_ili,
unweighted_ili,
ili_total,
total_patients,
pi_deaths,
percent_pi,
t2m_mean,
rh2m_mean,
precip_sum
) %>%
collect() %>%
# climate ends at 2024, so drop 2025
filter(year <= 2024) %>%
mutate(
pandemic = if_else(year %in% 2020:2021, 1L, 0L)
)
#Building Data for modeling (OPD/Climate)
# Model A: ILI ~ climate only (2010–2024)
model_df_A <- ili_tbl %>%
inner_join(
clim_wk,
by = c(
"state_id",
"state_abbr",
"year",
"week",
region = "state_name"
)
) %>%
select(
state_id,
state_name = region,
state_abbr,
year,
week,
weighted_ili,
unweighted_ili,
ili_total,
total_patients,
t2m_mean,
rh2m_mean,
precip_sum
) %>%
collect() %>%
mutate(
pandemic = if_else(year %in% 2020:2021, 1L, 0L)
)
# Adding lag features to Model
# ---- Add lags for Model A (ILI + climate) ----
model_A <- model_df_A %>%
arrange(state_id, year, week) %>%
group_by(state_id) %>%
mutate(
# ILI lags
ili_lag1 = lag(unweighted_ili, 1),
ili_lag2 = lag(unweighted_ili, 2),
ili_lag3 = lag(unweighted_ili, 3),
ili_lag4 = lag(unweighted_ili, 4),
# Climate lags (mean weekly)
t2m_lag1 = lag(t2m_mean, 1),
t2m_lag2 = lag(t2m_mean, 2),
t2m_lag3 = lag(t2m_mean, 3),
t2m_lag4 = lag(t2m_mean, 4),
rh2m_lag1 = lag(rh2m_mean, 1),
rh2m_lag2 = lag(rh2m_mean, 2),
rh2m_lag3 = lag(rh2m_mean, 3),
rh2m_lag4 = lag(rh2m_mean, 4),
precip_lag1 = lag(precip_sum, 1),
precip_lag2 = lag(precip_sum, 2),
precip_lag3 = lag(precip_sum, 3),
precip_lag4 = lag(precip_sum, 4)
) %>%
ungroup() %>%
# drop early weeks where lags are NA
filter(!is.na(ili_lag4))
# ---- Add lags for Model B (ILI + climate + mortality) ----
model_B <- model_df %>%
arrange(state_id, year, week) %>%
group_by(state_id) %>%
mutate(
# ILI lags
ili_lag1 = lag(unweighted_ili, 1),
ili_lag2 = lag(unweighted_ili, 2),
ili_lag3 = lag(unweighted_ili, 3),
ili_lag4 = lag(unweighted_ili, 4),
# Climate lags
t2m_lag1 = lag(t2m_mean, 1),
t2m_lag2 = lag(t2m_mean, 2),
t2m_lag3 = lag(t2m_mean, 3),
t2m_lag4 = lag(t2m_mean, 4),
rh2m_lag1 = lag(rh2m_mean, 1),
rh2m_lag2 = lag(rh2m_mean, 2),
rh2m_lag3 = lag(rh2m_mean, 3),
rh2m_lag4 = lag(rh2m_mean, 4),
precip_lag1 = lag(precip_sum, 1),
precip_lag2 = lag(precip_sum, 2),
precip_lag3 = lag(precip_sum, 3),
precip_lag4 = lag(precip_sum, 4)
) %>%
ungroup() %>%
# Remove early rows that have NA lags
filter(!is.na(ili_lag4))
#Splitting data in training and testing
## Since 2020 and 2021 were peak pandemic period, they can skew the data so they will be separated
set.seed(123)
# Model A splits (ILI + climate, pre-pandemic training)
A_train <- model_A %>% filter(year >= 2010, year <= 2019)
A_pand  <- model_A %>% filter(year %in% 2020:2021)
A_post  <- model_A %>% filter(year >= 2022, year <= 2024)
# Model B splits (ILI + climate + mortality, 2016+)
B_train <- model_B %>% filter(year >= 2016, year <= 2019) %>%
filter(!is.na(percent_pi))
B_pand  <- model_B %>% filter(year %in% 2020:2021)
B_post  <- model_B %>% filter(year >= 2022, year <= 2024)
full_df <- ili_tbl %>%
left_join(mort_tbl, by = c("state_id","state_abbr","year","week")) %>%
left_join(clim_WK, by = c("state_id","state_abbr","year","week")) %>%
arrange(state_name, year, week)
View(clim_wk)
full_df <- ili_tbl %>%
left_join(mort_tbl, by = c("state_id","state_abbr","year","week")) %>%
left_join(clim_WK, by = c("state_id","state_abbr","year","week")) %>%
arrange(state_name, year, week)
full_df <- ili_tbl %>%
left_join(mort_tbl, by = c("state_id","state_abbr","year","week")) %>%
left_join(clim_wk, by = c("state_id","state_abbr","year","week")) %>%
arrange(state_name, year, week)
saveRDS(full_df, "full_df.rds")
ne_states <- c("ME","NH","VT","MA","RI","CT","NY","NJ","PA")
ne_geom <- states(cb = TRUE, year = 2021) %>%
filter(STUSPS %in% ne_states) %>% st_transform(4326) %>%
select(state = STUSPS, geometry, NAME)
library(sf)
library(tigris)
ne_states <- c("ME","NH","VT","MA","RI","CT","NY","NJ","PA")
ne_geom <- states(cb = TRUE, year = 2021) %>%
filter(STUSPS %in% ne_states) %>% st_transform(4326) %>%
select(state = STUSPS, geometry, NAME)
saveRDS(ne_geom, "ne_geom.rds")
